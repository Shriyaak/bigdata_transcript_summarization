SPEAKER 0
They did everything. They could. So the assessment is actually. I saw that you have a procedure so that you have. She's. Right. But I think.

UNKNOWN
I don't. In terms.

SPEAKER 0
Of years, I believe I will, I will. You can't make me cry. As I said, the last week was at 1:00 on Tuesday, which stated in the announcement. Okay, okay.

UNKNOWN
Borussia Dortmund. Classes.

SPEAKER 0
So. So. So. Yeah. So there's no there's no assessment attached. Well, I do expect you to.

SPEAKER 1
So the office tower is the same.

SPEAKER 0
Okay. That. Hi. You. Not. You. How do you put it out? It is not. Have.

SPEAKER 1
I have. Hi. Good morning everybody. So welcome to week week two. So we're getting started. And as I mentioned last week. This week we're going to be looking at probability. So what we're going to be doing is introducing some of the mathematical background to probability. We won't go into the full mathematical detail, but it's useful for us to give some of the definitions of what I mean by sample space and events, but then go and state the axioms. So the building blocks of probability will introduce probability as a measure. And we'll think about what does that mean for us. And then we'll go and look at extensions. So the concept of conditional probability. What happens if we have two events. What about if one event the outcome of one event affects the outcome of the other. How do we account for that in probabilities. We'll talk about independence. So that's basically the special case where we have two events which they don't interact with each other. And finally we'll move on to at the end of this week. Talk about random variables and distributions. So often if you like it when we're talking about probability, there's many, many possible outcomes. But we're not interested in the individual outcomes. We're interested in some summary of them. So for example if I toss a coin 100 times there's two to the power 100 possible outcomes that can happen in terms of sequences. But I'm probably not interested in those individual sequences. What it might be interested in is how many heads I get along with that. We'll talk about expectation of variance. So the final two topics when we talk come on to talk about random variables. We're very much lead into where we go next week where we talk about some standard probability distributions. And then those will be used quite extensively. When we go on to talk more about statistical methods and actually fitting the probability distributions to data. So we have to start off with is the concept of a sample space. So sample space which is often denoted by omega which is about as far as the mathematical notation get is the set of all possible outcomes of a random experiment. So two things here we can think about experiment. So that can be in terms of sort of an experimental design. We set up the conditions and we observe the randomness. Or it could be that we actually observe what's going on in the real world. For example lots of you will be interested in ultimately, perhaps in finance. And if we're looking at stock markets, they could go up. They could go down. So there'll be a certain probability that will go up a particular stock. So the probability will go down. And we can look at modelling those. And when going to talk about an event it's a set of outcomes to which we can assign a probability. So we can assign some measure. And we'll talk about that in a moment. So for probability lectures like myself we like nice simple examples involving dice or coins, which is where we'll start off on this slide. Then we'll move on to a couple of more interesting ones on the next slide. So if I throw a die the singular of dice, then what's my possible set of outcomes? So I'm assuming here I've just got an ordinary six sided dice numbered in the conventional way. Then my set of possible outcomes will just be the numbers one, 3 to 6. As I say, my second example is I collect two coins. So coins would just say they can come up heads or tails. So I'm going to assume that I've got two distinct coins. So perhaps a pound coin and a penny. I'll write the outcome of the pound coin first. So we could have the outcome that both of them show heads. Or we could have a head on the pound coin and a tail on the penny. Alternatively, tail on the pound coin and head on the penny. Or we could have that. They're both shown tails. So if we look at this flipping two coins, what we've got is four possible outcomes. Key thing to note is that a head on the pound coin and a tail on the penny is a different outcome to a tail on the pound coin and a head on the penny. But when we come on to looking at random variables, we might only be interested in how many heads there are. And in that case, we don't. We're not really so worried about the distinction between these two cases. So it's important to think about what is important to us. Is it those individual outcomes, or is it just how many, in this case how many heads we have? So both of these examples so far are sample space. Our set of a possible outcomes has be finite. So the six possible outcomes involving a die. There are four possible outcomes when we toss two pots. What about if we toss a coin until a head appears? What's our possible outcomes? So we could have a head with the first toss of the coin. Or we could have a tail followed by a head. Or we could have two tails, followed by a head, and so on. We can have any number of tails followed by head. So here what we've got is we've got infinitely many possibilities. We can just think of any length of tails followed by head. But we've got a discrete countable set of outcomes. So in mathematics when we talk about things being countable, as the name suggests, we can count them. We can go, well, the first outcome is we get a head first time outcome two is we get a head second time on our second toss. Outcome three we get a head on a third. So we can easily enumerate them. The last two examples are going to give. We have examples of uncountable. So we might be interested in the time until a volcano next erupts. So what's our state space sample space there? So we have t the time until something occurs. We're looking at some time in the future, so we'll take T to be positive. But it could be happening at any time. So here we are using a continuous scale. So mathematical sense it's understandable that we cannot just enumerate each of the possible outcomes. It could even be infinity. The volcano might never erupt again. So if a volcano becomes dormant then you know there is the possibility it will never erupt. Another example is if we have a target here, I've just taken a circular target radius one, and we throw a dart at it and assume that you're better at dance than I am. You actually hit the target. Then we can look at the location of where you hit. So here I've got the centre of the target. I'm just going to give as a reference point. So x y coordinate zero zero. And we've got a target of radius one. So what can we think about that if we think about next y coordinate. So x in the whole of central direction and y in the vertical phase will just be the point where x squared plus y squared is less than or equal to one. So in particular I've just put in here the points. So where x is minus a quarter and y is .15. So again here we've got a finite area. But the possible location is on a on a continuous scale. So what we're going to be looking at is outcomes which are both discrete outcomes which we can easily count enumerate. And often those will be finite. But there might be infinite. But also we'll be looking at examples like this where we'll have a continuous spectrum of outcomes. So we said briefly something about sample space. So what do I mean by probability? So I've deliberately talked about probability as being a measure from a mathematical point of view. Measures measure theory important subject. But what are the common things we will use to measure things? Measure time. That's the time of the lecture. 50 minutes. That is, assigning a measurement length of an object weight. These are all measures. So what are some common features of measures that positive. So all of us have a mass. We all have a weight. And that weight is positive. It's additive. If we look at, say, lift lifts will often have a weight limit or person limit. And if we have five people going into the left, what's the total weight. People in the left. Well we just take each individual weight enough. And these are things which probability will have probabilities of positive I should say perhaps more strictly. They're non negative and they're additive. So if we have no overlap we can just add up the probabilities in the same way as if I'm looking at the weight of people in the lift. None of us share mass. So what we're doing if I want to know the total weight, I'm just adding up the individual weights of the individuals and we'll be doing the same thing with probability. Where probability sort of differs is it's a finite scale. So we have zero one which is common to other measures. And we have one as enough of that. So we're looking at things like weight mass. We can just keep on adding individuals. We perhaps have an upper limit the total weight of the mass of the universe. But we won't go into philosophical questions like this. We have a scale which is potentially infinite. So what are we going to be looking at is then we have our sample space. So again what I've come to is rolling a dice. We have the outcomes one up to six. We can now define our event. As I said an event is a collection of outcomes. So here I've chosen the outcomes to just be that we have an even number for the numbers two, 4 or 6. So the question then becomes how likely is it we roll an even number. So what we're going to do is we're going to assign a probability to this event. And what we're told is our probability will lie somewhere between 0 and 1. So we'll come back to answering this in a minute. So what are the sort of the motivations? We have the one or the probability of an event being one is if it's certain we know it's going to happen. So if I say I roll a die. I'm interested in the events. I roll A11 through a number between 1 and 6 inclusive. Well, assuming that my diet is numbered one through to six, when I roll it, I'm bound to get the number one through to six. Another important concept is probability of an impossible event, and probability of possible event is zero. So that's saying, well, what's the chance I roll a seven with a six sided dice. Number one six. I have no chance of doing that. I assume. Well, I assign zero weight to that. So we can think about this with other measures. So where we have. A non entity we could say well nothing has weight. Zero has leant zero. And. What we're doing if we. If we look at that, we're giving it a measure which is equal to zero. And we can do the same thing with probability, with an impossible event, we just give it essentially a weighting. But if probability was only on zero one in possible or certain events, it would be uninteresting. So where we're interested really is where we've got uncertainty. So where the outcome can lie somewhere between it is possible but it's not certain. So what do we have? Well, we have that if an event is very likely, it's going to have a probability close to one. If it's close to certain, we want that measure to be close to one or the other. And if event is very unlikely we want its chances to be close to zero. So we might think about something like winning a lottery. That's a very unlikely event. So our assignment, our wait for that probability is going to be close to zero. And we'll look at later in the lecture. Well, what's the probability of winning the UK lottery? What we want in between that is in the middle. If something is about is is equally likely to happen, does not happen, then we want a probability close to 0.5. So going back to rolling our dice, the outcome of an even number the spread chart three chances of that. But there's also three chances one, 3 or 5 of not getting an even number, i.e. getting an odd number. So we. What if. If something is equally likely to happen, it's not happen. A measure in the middle of 0.5. So we can represent this diagrammatically. So the one edge we've got the probability of the impossible event. Probability zero probability of a certain event at the other end. One in the middle. We've got a 5050 chance. Well that's just coming from saying 50% 50%. So that's looking at dividing up equally likely yes or no. One key point to make for this course when talking about probabilities, I do not want to ever see percentages. We're talking about when we're talking about probability. We'll be talking on a scale 31 when we come on to talk about some of the statistical concepts, then we very much will be talking in terms of percentages. We'll talk about confidence levels. Significance levels. Those are typically are represented as as percentages. But if we're asking a sort of mathematical question involving probability, we're working on the scale 0 to 1. Whether you give a decimal or a fraction either is fine. So how do we represent a probability. So we just use P to represent a probability a measure. And we assign a probability to an event okay. So the key point from what we've said so far is that when we assign probability to an event that's going to lie somewhere between 0 and 1 and close it. So the sort of final bit before I actually give the axioms probability is just to represent some set notation. So give give you some idea what I talk about when I'm talking about for example intersection union complement of events. So what I'm going to use to illustrate this as I'm going to stick with a dice example. So I'm going to take my set A to just be the even numbers. So the set that we were interested in before. So what I could do is I could draw a diagram of my sample space, Omega, my set in the middle A contains the elements two, four and six and everything outside that is the complement. So I would typically denote complement is a with a superscript c. You might also very often see a with a bar across the top. So it's anything which is in my sample space but is not the particular event I'm interested in. So here this is going to be the opposite. So one three and five. So a couple of important special cases. What's the complement of the whole sample space a whole set of outcomes. This is known as the empty set. So if I've got the whole sample space as my event what's left over. Well nothing's left over. So that's the empty set. Similarly the complement of the empty set. I.e. everything which is not in the empty set. This is going to be the whole set of outcomes. Next we have intersection. So as well as letting a be the even numbers. What I'm going to do is let B be the outcomes from rolling a dice which are divisible by three, so 3 or 6. So what we have here is a intersection b. I just everything which occurs in both. So six is both even and divisible by three. We have three which is divisible by three, which is but not even. And we have a couple of numbers two and four, which are even, but not limited by three as we had before. We can complete our picture by just adding one and five here. They are neither divisible by three, so that again gives us our full set of outcomes for our dice. We will often be interested in the case where the intersection is the empty set. So I'm going to stick for this example with a big the even numbers two, four and six. I might take my set V here just to be the event that I go to one. So in this case we have no overlap between the two events. So if I tell you that A has occurred, that will necessarily mean that I'm not going to one. Conversely, if I tell you I've rolled a one that tells me that I can't have got an even number. So they both can't occur together. This particular example, then we've got two events again which don't appear in either. So three and five don't appear in a and don't appear to be. So we talked about intersection. So that's saying that both the two events occur. We can also look at the union. So a union B the union of A and B is the event that at least one of A or B occurs. So I'm going back here now to my b being 3 or 6. The two divisible by two numbers. We should do this by three sticking with a big two 4 or 6. So the even numbers. So what's the union. So as we have before I can put these together. So we had six occurs in both. Three is divisible by three. But not even two and four are both even but not by three. So you have exactly the same diagram as we had before. But rather than just being interested in the intersection. So where they overlap, we're interested in the outcomes which occur in at least one of them. So the union here is just going to be all those numbers two, three, four and six which are either divisible by three or even. Again, we could, if we want for completeness, include those numbers which don't lie neither. Okay. Okay. So now we're in a position to give the actions of probability. So a probability measure is a real valued function. So what does that mean. So all that means is that our probabilities will take an object i.e. event and assign a numerical value to it. And that numerical value will be some real number between 0 and 1. So what are the key points? We have the probability of any events. P of A is positive or at least non-negative. It could be equal to zero. And we have additivity if and b two disjointed events also known as mutually exclusive, then the probability of a or b occurring is just the probability of a plus probability of B. So going back to our earlier discussion of measures, axioms a1, a2, a3, essentially shared by all measures. So if we go back to weight mass, we're assigning a weight to each individual that's going to be positive if we have two separate individuals who share. So no weight, then the combined weight is just weight of one and the weight of a given. Now it is important that we have that this is disjoint. So again thinking about measures. If you are unfortunate enough to be convicted of a convicted of crimes, you might have multiple sentences handed down to you. And those sentences could run in series. So one after another or they could run concurrently. So if you were given a five year sentence and a two year sentence to run concurrently, essentially what you'd be doing for the first two years is serving both sentences until the first one finishes, and then you'll be continuing with the second one. So there is a situation where we have overlap, but the same will happen with probabilities. So when we talk about the probability of A or b here, we say, well if they have nothing in common, just add up their probabilities. But if there is some intersection. So going back to the example we had before where A was just the even numbers two for six and b was 3 or 6 and divisible by three, the probability of at least one of these occurring is not going to be the probability of a plus the probability of B, because what we have is we have some overlap which essentially results in double counting. So say the part before we move on and look at using these axioms and what we can derive from them. Know the final one is the one which is special to probability. This finite element that the probability of the whole sample space. It says our maximum value is equal to one. Okay. I think that's a good place. Just to have a minute sort of break for you to take things in. And then we'll look at, as I say, using the axioms.

SPEAKER 0
That's. Not a cause. For change. It was very. Much.

SPEAKER 1
Okay, so look at on with the second half of of the lecture. So. All right. So just a couple of sort of housekeeping things. You know, where the reason I give you a break in the middle is it gives you a chance to actually just have a stop, have a chat if you want to. But when we say to come back into the lecture, I appreciate it if you stop talking also in the lecture does start at 9:00. I appreciate that sometimes you will arrive late, but do minimise the disruption you cause. If you do arrive at a lecture late. Okay, so axioms are the building building blocks. So from from the axioms we derive everything else. So the first one is principle of inclusion exclusion. So the probability of a compliment is just equal to one minus the probability of a. So this comes from the fact that we can split our sample space into the intersection of A and a complement. So going back to our nice example, if I say a is the even numbers are set, a complement is just going to be the odd numbers. And one of those must occur. But they both can't okay. Leading on from that. And the fact that if we take a to be the sample space, then a complement in that case would be the empty set. So the probability of the empty set probability we assigned to something which is impossible to occur is equal to zero. Secondly, we'll say, thirdly, we have monitored this city. If A is a subset of B, then the probability of A occurring is less than or equal to the probability of B. So in other words, if I'm interested in the total weight of everybody in in this lecture theatre, well that's going to be greater than the total weight of everybody in the front row, because the goes in the front row is just a subset of the whole. So we've got, if you like, the weight of then and what we want to then what to do is add on the weight of BHS. Something we've already touched on from the axioms. We've got this new bound. So the first axiom states that the probability of A is positive doesn't put an upper bound on it, but it says well the probability of the whole sample space is equal to one. And if we combine that with monitor, this study that says that any event we have must have upper bound probability of one. The final one is the law of addition. So this is useful result if we want the probability of at least one of two events occurring A or b, we add up the two individual probabilities and then we take off. And I think we've double counted I think they have in common. So if we look at axiom three that's in the case where A and B are an empty set they have nothing in common. Now we go back to the second statement. Here. The probability of the empty set is equal to zero. So if this is equal to zero then we just get back to the probability A or b occurring. It's just probability of a plus the probability of b. Counting. So certainly when we introduce probability, accounting plays a key role. A lot of the situations we look at we have that our sample space has n possibilities. So if we're looking at this example and would be six we had earlier, flipping two coins instead of possibilities is four. We're going to come on to an example in a bit which has a lot more much larger N, which is when we come to a lottery, then we have 59, two, six possibilities. Come on to all. That is the moment. Now we might have in many situations where each of the individual outcomes are equally likely. So if we take a dice, we're assuming it's fair. And by being fair, we're saying, well, actually each of the numbers one through to six is equally likely to appear. So the probability of any element, any sort of single outcome is just going to be one over eight. Then if we take our event that we're interested in. So that will be some subset of our sample space. In other words some collection of events we want the probability of occurring. We just say well how many elements are there in E divided by n. So for example, if we want an even number. From rolling a dice, how many even numbers are there on a dice? There are three. What's the total number of possibilities to six? So our probability of getting an even number is just going to be three over six. So one and two. And this is intuitive. Perhaps our even if we've not looked formally at probability or chance before. This is how we probably use to describe the things a one and two chance basically 5050. So we can think again of tossing a coin and we can say, well, the same chance it ends up heads as it ends up tails one and two. So sticking with our dice example. So what we could do is go back to the example we had before. We've just touched upon the probability of a gain even number that is three over six. What about if our event is B so that B from before was the event that we got a number which is divisible by three, so 3 or 6. So I tell you the same principle here. The probability of b is just going to be two over six. So now if I want the probability of A or b. This is going to be the probability of A plus the probability of b minus the probability of the intersection. So what we have is this is equal to three over six plus two over six. And as we said before how many elements are in the overlap. Well the only element that these two have in common is the number six. So the probability of in this case the intersection is just going to be one sixth. So we've got three three over six plus two over six which could be five six minus one six which is four over six. Certainly in this case we could have got at that directly. We could have just said, well my set A Union B as we saw before was just two, three four, six. Let me just say well that has four elements. So 4/6. But in general it might be or it is often easier to build things up and say what's the individual probabilities. What's the probability of the intersection. And that will then give us the probability of the union. Just a slightly more evolved example. This involving my my probably third favourite example of the dice of coins pocket playing cards. So here we have of ordinary playing cards. So we have four suits clubs, diamonds apart, spades, and in each suit we have 13 cards ace i.e. one through to ten. And then Jack Queen kit. So clubs and spades are both black hearts and diamonds. So what is the probability that the card is either black or a king? So we can let B be the event that we get a black card. Okay. B the event that we get a king. And we also can get a black king. So either the king spades or the King of clubs. So there are 26 black cards. 213 there are four kings, one for each suit. And as we've already just mentioned, there are two in the bottom. Two black.

SPEAKER 0
Kings.

SPEAKER 1
So here, if we want the probability black or king probability black, plus the probability of the king minus the ones we counted twice, which will be the white case. So that would be 26 over 52 plus four over 52 minus two over 52. So seeing as we've got a common divisor but everything over 52, we get 28 over 32 which simplifies to seven over 30. So with these kind of questions it's often natural just to write them as fractions. But as I said earlier on in the lecture, I'd be very happy in any exam for you to give it as a decimal instead. So sort of following on from the sort of general rule of counting, we have multiplication. So this crops up quite a bit in how how we count on it. So the first thing is, the number of ways of selecting one object from an is just just add possibilities. So I say say 80 people in this lecture theatre. If I do 80 choices I could make from choosing an individual. The number of ways of selecting one object from n and another one object from m is just n times m. So instead of just choosing one person at random from the lecture theatre, I might segregate you. Male and female. Pick one male, one female. So far 45 males, 35 females. Then the number of possible pairings I have is 45 times 35. In other words, I could just combine any male with any female. Well, we can just build this up in stages rather than just looking at two. We can have k distinct stages, and if at stage R I have no choices then the number of possible outcomes is n one times n two all the way up to times n k. So one possible example of that is I get to choose, you know, some sort of order. So I randomly choose one person. They come down over here, I then pick somebody else. They come down next to them. I then randomly choose somebody else. So there we might start up with 80 people. And once I've chosen one person. We've only got 79 choices left. After I've chosen two people, we only got 78. So quite often we will have this decreasing sequence one by one. And this leads us nicely on to the up factorials. So factorials play a key role. So n with an exclamation mark. And that is the number of possible ways we can order an object. So let's say we have n choices of who we choose first. We have n minus one choices for who we choose second, and so on. And by the time we get to the last individual who's left sitting down while standing up, I've got no choice. You are. You are the one who makes it final. So just one thing to say. A mathematical convention, which is very useful, is that zero factorial is heavy. And unsurprisingly, factorials grow pretty quickly. So 1234 factorial. So if we take four factor that's four times three times two times one, that's just 24. By the time we get up to ten. So ten times nine times eight and so on. We're already over 3.6 million and they grow very rapidly. So we can see that the number of possible ways of ordering everybody in this lecture theatre would be astronomical. So let's have a look at what's the probability of you winning the lottery, which is not extra large. It's going to be very small. So how does the UK lottery work? Well, there are 59 numbers now, just in the numbers 1 to 59. And you pick six numbers so you win. If when the lottery is drawn the six numbers drawn out are your numbers. So the numbers are drawn one at a time. So we're going back into this factorial sort of thing until six numbers will be drawn. So there are 59 choices for which number will come out first. 58. So how many choices per second all the way down to the sixth number, where there'll be 53 choices. So if you do 59 times 58 so I'm down to 53. We get this number here which is $32. What about your chance of winning. How many ways could your numbers occur. Well you have six numbers. So you've got essentially six choices for your first number. Let's say you've been unimaginative and gone for the numbers 1 to 6. So first number out is number one. That leaves five numbers to be selected from. Once your second numbers come you've got four which are third numbers coming up three. So there's 720 different ways that your numbers could appear. And you're not bothered whether it's one through to six, six through to 1 or 1, three, five, followed by two, four, six. So if we do 720, the number of ways your numbers can appear divided by the total number of possibilities of six numbers, 32 million odds, we get about 1 in 45,000,000. So not a very good chance of winning the lottery. So if we all all played, let's say we've got let's say we've got about 90 people in here, then there would be about a 1.5 million chance. I mean, we all pick different, different sets of numbers that one of us will be a winner. So it should be none of this will be a winner. We'll see each other next. Next week's lectures. So what I want to finish off this lecture with now is the concept of conditional probability. So this is what we're going to expand upon in the second half of today's lecture. So at 12:00. So I'm a keen sports fan and can have a look at lots of different sporting examples. So looking at football football here. So we see the Manchester Manchester derby between Man City and Man United. And at the start of the game we think there's probability 0.6 the Man City will be Manchester United. Now the dream situation for any Manchester United fans. They find themselves four one up at half time. How would that affect our assessment of the probability of Manchester City winning the game? Well, we'd probably reduce our probability of them winning. Say well they're four one down. The guys go at least four goals without conceding. Probably their chances of winning would be much smaller. So what we've done is we've made use of some information to adjust that probability so that one's adjusted down. Second one is an example where we adjust our problem. So if we have two fair dice the probability of achieving a 12 when we roll them. So six on both dice. It's just going to be one over six times one over six. So one over 36. But now if I tell you that the first dice is showing a six, what our probability that overall will have a 12 will, all we need now is for the second dice to show a six. So again that will just be 1 in 6. So what we'll have then is that our probability goes from being 1 in 36 to 1 in 6. So here again essentially we've used the half time. The first roll is the first half second world second half. But we're going to look at how powerful this is as concept. And what we have is that the probability of conditional probability. So our probability of some event a conditional upon another event f. So I use a vertical line to denote the conditioning of on. So everything on the left hand side is the things we're uncertain about, things we're interested in calculating probability about. Everything which occurs on the right hand side is what we're conditioning upon what we know. So what's the probability of us getting a score of 12 overall, given that the first dice is a six? So to work this out we work out well. What's the probability of both events. 12 overall. And we get six with the first dice divided by the probability of the first event the probability. This is all well and good as long as we're not dividing by zero. So this is the case where our probability f is going to be greater than zero. The final point I want to note for this lecture is we've got commutativity. So we can write. If we're looking at the intersection of two events we can write E and F or we can write f. And so we can say what's the probability of e and f. We can first of all say well what's the probability of one of those events. Probability f. What's the probability we get a six with the first dice. And then look at the conditional probability of getting 12 overall given we've got a six. Or we can reverse that. And we can say well what's the probability of getting a 12 overall. And then the conditional probability that actually the first dice show the six. And that would be the example of a conditional probability where we'd have a certain amount. If I tell you that I've rolled two dice and scored a total score is 12, I say, well, what's the probability? My first dice was was a six. Well, you know, it's going to be a six because the only possible outcome to get 12 overall is two sixes. But this is very useful and we'll see. As I say in the second lecture today for using conditional probability, because often one of these conditional probabilities is easy to write down. The other one might be much harder. That might be what we're what we're really interested in. Okay. So we'll stop there for now. I'll see you again in two hour time in chemistry. I.
